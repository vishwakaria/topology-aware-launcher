{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Distributed data parallel MNIST training with PyTorch and SageMaker distributed\n",
    "\n",
    "## Background\n",
    "[Amazon SageMaker's distributed library](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html) can be used to train deep learning models faster and cheaper. The [data parallel](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html) feature in this library is a distributed data parallel training framework for PyTorch, TensorFlow, and MXNet. This notebook demonstrates how to use the SageMaker distributed data library to train a PyTorch model using the MNIST dataset.\n",
    "\n",
    "This notebook example shows how to use `smdistributed.dataparallel` with PyTorch in SageMaker using MNIST dataset.\n",
    "\n",
    "For more information:\n",
    "\n",
    "1. [SageMaker distributed data parallel PyTorch API Specification](https://sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel_pytorch.html)\n",
    "1. [Getting started with SageMaker distributed data parallel](https://sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel.html)\n",
    "1. [PyTorch in SageMaker](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html)\n",
    "\n",
    "### Dataset\n",
    "This example uses the MNIST dataset. MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** This example requires SageMaker Python SDK v2.**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker role\n",
    "\n",
    "The following code cell defines `role` which is the IAM role ARN used to create and run SageMaker training and hosting jobs. This is the same IAM role used to create this SageMaker Notebook instance. \n",
    "\n",
    "`role` must have permission to create a SageMaker training job and launch an endpoint to host a model. For granular policies you can use to grant these permissions, see [Amazon SageMaker Roles](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Amazon Resource Name (ARN) of the role used for this demo is: arn:aws:iam::570106654206:role/ziyi-dev\n",
      "The name of the role used for this demo is: ziyi-dev\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "role_name = role.split([\"/\"][-1])\n",
    "print(f\"The Amazon Resource Name (ARN) of the role used for this demo is: {role}\")\n",
    "print(f\"The name of the role used for this demo is: {role_name[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that the role above has required permissions:\n",
    "\n",
    "1. Go to the IAM console: https://console.aws.amazon.com/iam/home.\n",
    "2. Select **Roles**.\n",
    "3. Enter the role name in the search box to search for that role. \n",
    "4. Select the role.\n",
    "5. Use the **Permissions** tab to verify this role has required permissions attached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training with SageMaker distributed data parallel\n",
    "\n",
    "### Training script\n",
    "\n",
    "The MNIST dataset is downloaded using the `torchvision.datasets` PyTorch module; you can see how this is implemented in the `train_pytorch_smdataparallel_mnist.py` training script that is printed out in the next cell.\n",
    "\n",
    "The training script provides the code you need for distributed data parallel (DDP) training using SageMaker's distributed data parallel library (`smdistributed.dataparallel`). The training script is very similar to a PyTorch training script you might run outside SageMaker, but modified to run with the `smdistributed.dataparallel` library. This library's PyTorch client provides an alternative to PyTorch's native DDP.\n",
    "\n",
    "For details about how to use `smdistributed.dataparallel`'s DDP in your native PyTorch script, see the [Modify a PyTorch Training Script Using SMD Data Parallel](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp.html#data-parallel-modify-sdp-pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize code/train_pytorch_smdataparallel_mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator function options\n",
    "\n",
    "In the following code block, you can update the estimator function to use a different instance type, instance count, and distribution strategy. You're also passing in the training script you reviewed in the previous cell to this estimator.\n",
    "\n",
    "**Instance types**\n",
    "\n",
    "`smdistributed.dataparallel` supports model training on SageMaker with the following instance types only.  For best performance, it is recommended you use an instance type that supports Amazon Elastic Fabric Adapter (ml.p3dn.24xlarge and ml.p4d.24xlarge).\n",
    "\n",
    "1. ml.p3.16xlarge\n",
    "1. ml.p3dn.24xlarge [Recommended]\n",
    "1. ml.p4d.24xlarge [Recommended]\n",
    "\n",
    "**Instance count**\n",
    "\n",
    "To get the best performance and the most out of `smdistributed.dataparallel`, you should use at least 2 instances, but you can also use 1 for testing this example.\n",
    "\n",
    "**Distribution strategy**\n",
    "\n",
    "Note that to use DDP mode, you update the `distribution` strategy, and set it to use `smdistributed dataparallel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.instance_group import InstanceGroup\n",
    "\n",
    "\n",
    "group1 = InstanceGroup(\"spine1\", \"ml.c5n.2xlarge\", 4)\n",
    "group2 = InstanceGroup(\"spine2\", \"ml.c5n.2xlarge\", 4)  \n",
    "\n",
    "\n",
    "estimator = PyTorch(\n",
    "    base_job_name=\"pytorch-smdataparallel-mnist\",\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"entry_point.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.11.0\",\n",
    "    py_version=\"py38\",\n",
    "    # For training with multinode distributed training, set this count. Example: 2\n",
    "    #instance_count=4,\n",
    "    # For training with p3dn instance use - ml.p3dn.24xlarge, with p4dn instance use - ml.p4d.24xlarge\n",
    "    #instance_type=\"ml.c5n.2xlarge\",\n",
    "    instance_groups = [group1, group2],\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    # Training using SMDataParallel Distributed Training Framework\n",
    "    debugger_hook_config=False,\n",
    "    #keep_alive_period_in_seconds=1800,\n",
    "    hyperparameters = {'pp-degree': 4, 'dp-degree': 2,\n",
    "                       'optimize-for-pp': 'False', 'dp-major': 'True', 'entry-point': 'hello.py',\n",
    "                       'flag1' : 'flag1_val', 'flag2' : 'flag2_val', 'flag3': None}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Now that you have a trained model, you can deploy an endpoint to host the model. After you deploy the endpoint, you can then test it with inference requests. The following cell will store the model_data variable to be used with the inference notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = estimator.model_data\n",
    "print(\"Storing {} as model_data\".format(model_data))\n",
    "%store model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.instance_group import InstanceGroup\n",
    "\n",
    "s3_train_bucket = \"s3://viskaria/enwik8\"\n",
    "\n",
    "train = sagemaker.inputs.TrainingInput(\n",
    "            s3_train_bucket, distribution=\"FullyReplicated\", s3_data_type=\"S3Prefix\"\n",
    "        )\n",
    "data_channels = {\"train\": train}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    base_job_name=\"topology-inference-mpi\",\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"topology_aware_launcher.py\",\n",
    "    role=role,\n",
    "    image_uri=\"570106654206.dkr.ecr.us-east-1.amazonaws.com/megatron-deepspeed:pt1.13.1-deeperspeed-0.8.3-v1\",\n",
    "    # For training with multinode distributed training, set this count. Example: 2\n",
    "    instance_count=8,\n",
    "    # For training with p3dn instance use - ml.p3dn.24xlarge, with p4dn instance use - ml.p4d.24xlarge\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    # Training using SMDataParallel Distributed Training Framework\n",
    "    debugger_hook_config=False,\n",
    "    keep_alive_period_in_seconds=1800,\n",
    "    hyperparameters = {'pp-degree': 4, 'dp-degree': 2,\n",
    "                       'optimize-for-pp': 'False', 'dp-major': 'True', \n",
    "                       'entry-point': 'gpt-neox/train_torchrun.py', \n",
    "                       'conf': 'gpt-neox/sai_vishwa_15B.yml', \n",
    "                       }\n",
    ")\n",
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Megatron+DS with gpt-neox "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure FSx Input for your SageMaker Training job\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "# FSx file system ID with your training dataset. Example: 'fs-0bYYYYYY'\n",
    "file_system_id = \"fs-058ddb4f9d002316a\"\n",
    "# FSx path with your training data # Example: '/fsx_mount_name/imagenet'\n",
    "file_system_directory_path = \"/evoynbev/enwik8\"\n",
    "file_system_access_mode = \"rw\"\n",
    "file_system_type = \"FSxLustre\"\n",
    "train_fs = FileSystemInput(\n",
    "    file_system_id=file_system_id,\n",
    "    file_system_type=file_system_type,\n",
    "    directory_path=file_system_directory_path,\n",
    "    file_system_access_mode=file_system_access_mode,\n",
    ")\n",
    "# Specify the training data channel using the FSx filesystem. This will be provided to the SageMaker training job later\n",
    "data_channels = {\"train\": train_fs}\n",
    "\n",
    "# The following variables will be used later in the notebook\n",
    "subnets = [\"subnet-8caa97c1\"]  # Should be the subnet used for FSx. Example: subnet-0f9XXXX\n",
    "security_group_ids = [\"sg-fa5abbfb\"]  # Shold be the security group used for FSx. sg-03ZZZZZZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_train_bucket = \"s3://viskaria/enwik8\"\n",
    "\n",
    "train = sagemaker.inputs.TrainingInput(\n",
    "            s3_train_bucket, distribution=\"FullyReplicated\", s3_data_type=\"S3Prefix\"\n",
    "        )\n",
    "data_channels = {\"train\": train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: topology-inference-mpi-2023-05-02-01-21-31-358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-02 01:21:33 Starting - Starting the training job...\n",
      "2023-05-02 01:21:42 Downloading - Downloading input data\n",
      "2023-05-02 01:21:42 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-05-02 01:21:54,822 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-05-02 01:21:54,883 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-02 01:21:54,892 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-05-02 01:21:54,894 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-05-02 01:21:55,189 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-02 01:21:55,261 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-02 01:21:55,332 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-02 01:21:55,342 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bad-placement\": false,\n",
      "        \"conf\": \"gpt-neox/sai_vishwa_15B.yml\",\n",
      "        \"dp-degree\": 1,\n",
      "        \"dp-major\": \"True\",\n",
      "        \"entry-point\": \"hello.py\",\n",
      "        \"optimize-for-pp\": \"True\",\n",
      "        \"pp-degree\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"topology-inference-mpi-2023-05-02-01-21-31-358\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-570106654206/topology-inference-mpi-2023-05-02-01-21-31-358/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"topology_aware_launcher\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"topology_aware_launcher.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bad-placement\":false,\"conf\":\"gpt-neox/sai_vishwa_15B.yml\",\"dp-degree\":1,\"dp-major\":\"True\",\"entry-point\":\"hello.py\",\"optimize-for-pp\":\"True\",\"pp-degree\":2}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=topology_aware_launcher.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p4d.24xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=topology_aware_launcher\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-570106654206/topology-inference-mpi-2023-05-02-01-21-31-358/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p4d.24xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"bad-placement\":false,\"conf\":\"gpt-neox/sai_vishwa_15B.yml\",\"dp-degree\":1,\"dp-major\":\"True\",\"entry-point\":\"hello.py\",\"optimize-for-pp\":\"True\",\"pp-degree\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"topology-inference-mpi-2023-05-02-01-21-31-358\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-570106654206/topology-inference-mpi-2023-05-02-01-21-31-358/source/sourcedir.tar.gz\",\"module_name\":\"topology_aware_launcher\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"topology_aware_launcher.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bad-placement\",\"False\",\"--conf\",\"gpt-neox/sai_vishwa_15B.yml\",\"--dp-degree\",\"1\",\"--dp-major\",\"True\",\"--entry-point\",\"hello.py\",\"--optimize-for-pp\",\"True\",\"--pp-degree\",\"2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_BAD-PLACEMENT=false\u001b[0m\n",
      "\u001b[34mSM_HP_CONF=gpt-neox/sai_vishwa_15B.yml\u001b[0m\n",
      "\u001b[34mSM_HP_DP-DEGREE=1\u001b[0m\n",
      "\u001b[34mSM_HP_DP-MAJOR=True\u001b[0m\n",
      "\u001b[34mSM_HP_ENTRY-POINT=hello.py\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZE-FOR-PP=True\u001b[0m\n",
      "\u001b[34mSM_HP_PP-DEGREE=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 topology_aware_launcher.py --bad-placement False --conf gpt-neox/sai_vishwa_15B.yml --dp-degree 1 --dp-major True --entry-point hello.py --optimize-for-pp True --pp-degree 2\u001b[0m\n",
      "\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2023-05-02 01:21:54,835 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2023-05-02 01:21:54,897 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2023-05-02 01:21:54,906 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2023-05-02 01:21:54,908 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2023-05-02 01:21:55,214 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2023-05-02 01:21:55,286 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2023-05-02 01:21:55,357 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2023-05-02 01:21:55,367 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bad-placement\": false,\n",
      "        \"conf\": \"gpt-neox/sai_vishwa_15B.yml\",\n",
      "        \"dp-degree\": 1,\n",
      "        \"dp-major\": \"True\",\n",
      "        \"entry-point\": \"hello.py\",\n",
      "        \"optimize-for-pp\": \"True\",\n",
      "        \"pp-degree\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"topology-inference-mpi-2023-05-02-01-21-31-358\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-570106654206/topology-inference-mpi-2023-05-02-01-21-31-358/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"topology_aware_launcher\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"topology_aware_launcher.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"bad-placement\":false,\"conf\":\"gpt-neox/sai_vishwa_15B.yml\",\"dp-degree\":1,\"dp-major\":\"True\",\"entry-point\":\"hello.py\",\"optimize-for-pp\":\"True\",\"pp-degree\":2}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=topology_aware_launcher.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_TYPE=ml.p4d.24xlarge\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[35mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[35mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}}\u001b[0m\n",
      "\u001b[35mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[35mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=topology_aware_launcher\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-east-1-570106654206/topology-inference-mpi-2023-05-02-01-21-31-358/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p4d.24xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"bad-placement\":false,\"conf\":\"gpt-neox/sai_vishwa_15B.yml\",\"dp-degree\":1,\"dp-major\":\"True\",\"entry-point\":\"hello.py\",\"optimize-for-pp\":\"True\",\"pp-degree\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"topology-inference-mpi-2023-05-02-01-21-31-358\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-570106654206/topology-inference-mpi-2023-05-02-01-21-31-358/source/sourcedir.tar.gz\",\"module_name\":\"topology_aware_launcher\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"topology_aware_launcher.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--bad-placement\",\"False\",\"--conf\",\"gpt-neox/sai_vishwa_15B.yml\",\"--dp-degree\",\"1\",\"--dp-major\",\"True\",\"--entry-point\",\"hello.py\",\"--optimize-for-pp\",\"True\",\"--pp-degree\",\"2\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_HP_BAD-PLACEMENT=false\u001b[0m\n",
      "\u001b[35mSM_HP_CONF=gpt-neox/sai_vishwa_15B.yml\u001b[0m\n",
      "\u001b[35mSM_HP_DP-DEGREE=1\u001b[0m\n",
      "\u001b[35mSM_HP_DP-MAJOR=True\u001b[0m\n",
      "\u001b[35mSM_HP_ENTRY-POINT=hello.py\u001b[0m\n",
      "\u001b[35mSM_HP_OPTIMIZE-FOR-PP=True\u001b[0m\n",
      "\u001b[35mSM_HP_PP-DEGREE=2\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.9 topology_aware_launcher.py --bad-placement False --conf gpt-neox/sai_vishwa_15B.yml --dp-degree 1 --dp-major True --entry-point hello.py --optimize-for-pp True --pp-degree 2\u001b[0m\n",
      "\u001b[34m2023-05-02 01:21:59,259 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m2023-05-02 01:21:59,279 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mInit master worker\u001b[0m\n",
      "\u001b[34mStarting MPI run as master node.\u001b[0m\n",
      "\u001b[34mCreating SSH daemon.\u001b[0m\n",
      "\u001b[34mWaiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34mmaster checking connection to algo-2\u001b[0m\n",
      "\u001b[34mTesting connection to host algo-2\u001b[0m\n",
      "\u001b[34mConnection failed with exception: \n",
      " %s.              Can be ignored for worker when master completes and exits. [Errno None] Unable to connect to port 22 on 10.0.89.137\u001b[0m\n",
      "\u001b[35m2023-05-02 01:21:59,502 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[35m2023-05-02 01:21:59,523 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[35mInit worker runner\u001b[0m\n",
      "\u001b[35mWorker waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35mTesting connection to host algo-1\u001b[0m\n",
      "\u001b[35mCan connect to host %s algo-1\u001b[0m\n",
      "\u001b[35mMPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35mWriting environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35mWaiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34mTesting connection to host algo-2\u001b[0m\n",
      "\u001b[34mCan connect to host %s algo-2\u001b[0m\n",
      "\u001b[34mWorker %s available for communication algo-2\u001b[0m\n",
      "\u001b[34mEnv Hosts: %s Hosts: %s process_per_hosts: %s num_processes: %s ['algo-1', 'algo-2'] ['algo-1', 'algo-2'] 1 2\u001b[0m\n",
      "\u001b[34mRunnind command: `mpirun --host algo-1,algo-2 -np 2 --allow-run-as-root -mca orte_abort_on_non_zero_status 1 bin/ring_latency_calculator /opt/ml/code`\u001b[0m\n",
      "\u001b[34mWaiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.0.89.137' (ECDSA) to the list of known hosts.\u001b[0m\n",
      "\u001b[34mInitializing MPI...\u001b[0m\n",
      "\u001b[34mInitializing MPI...\u001b[0m\n",
      "\u001b[34m0: 2: pid = 130\u001b[0m\n",
      "\u001b[34m1: 2: pid = 138\u001b[0m\n",
      "\u001b[34moutput_dir = /opt/ml/code/\u001b[0m\n",
      "\u001b[34moutput_dir = /opt/ml/code/\u001b[0m\n",
      "\u001b[34mcurl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34mcurl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34mInstance id mapping: \u001b[0m\n",
      "\u001b[34mNode 0 - algo-1\u001b[0m\n",
      "\u001b[34mNode 1 - algo-2\u001b[0m\n",
      "\u001b[34m0: Loading EFA devices...\u001b[0m\n",
      "\u001b[34m1: Loading EFA devices...\u001b[0m\n",
      "\u001b[35mProcess[es]: %s\u001b[0m\n",
      "\u001b[35m[psutil.Process(pid=135, name='orted', status='running', started='01:22:00')]\u001b[0m\n",
      "\u001b[35mOrted process found %s\u001b[0m\n",
      "\u001b[35m[psutil.Process(pid=135, name='orted', status='running', started='01:22:00')]\u001b[0m\n",
      "\u001b[35mWaiting for orted process %s [psutil.Process(pid=135, name='orted', status='running', started='01:22:00')]\u001b[0m\n",
      "\u001b[34m0: All EFA devices have been loaded. Creating address handles now...\u001b[0m\n",
      "\u001b[34m1: All EFA devices have been loaded. Creating address handles now...\u001b[0m\n",
      "\u001b[34m0: Computing tolopogy information for the cluster...\u001b[0m\n",
      "\u001b[34m1: Computing tolopogy information for the cluster...\u001b[0m\n",
      "\u001b[34m0: Avg: 39.2767\u001b[0m\n",
      "\u001b[34m0: Buckets: 0 0 \u001b[0m\n",
      "\u001b[34mCompute time: 42 ms\u001b[0m\n",
      "\u001b[34mWriting topology to /opt/ml/code/cluster_topology.txt\u001b[0m\n",
      "\u001b[34m1: Avg: 39.1878\u001b[0m\n",
      "\u001b[34mWriting topology to /opt/ml/code/cluster_topology.txt\u001b[0m\n",
      "\u001b[34mDone waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34mReading topology mapping from file /opt/ml/code/cluster_topology.txt\u001b[0m\n",
      "\u001b[34mOutput from topology compute: {'spine1': ['algo-1', 'algo-2']} count: 2\u001b[0m\n",
      "\u001b[34mranking is ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34mLaunching job with command: torchrun --nnodes=2 --node_rank=0 --nproc_per_node=8 --rdzv_endpoint=algo-1:29400 --rdzv_id=100 hello.py --conf gpt-neox/sai_vishwa_15B.yml\u001b[0m\n",
      "\u001b[35mInvoked on_terminate from psutil.wait_for_procs\u001b[0m\n",
      "\u001b[35mprocess psutil.Process(pid=135, name='orted', status='terminated', started='01:22:00') terminated with exit code None\u001b[0m\n",
      "\u001b[35mReporting status for ORTEd process. gone: [psutil.Process(pid=135, name='orted', status='terminated', started='01:22:00')] alive: []\u001b[0m\n",
      "\u001b[35mOrted process exited\u001b[0m\n",
      "\u001b[35mMPI process finished, killing SSHD\u001b[0m\n",
      "\u001b[35mReading topology mapping from file /opt/ml/code/cluster_topology.txt\u001b[0m\n",
      "\u001b[35mOutput from topology compute: {'spine1': ['algo-1', 'algo-2']} count: 2\u001b[0m\n",
      "\u001b[35mranking is ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[35mLaunching job with command: torchrun --nnodes=2 --node_rank=1 --nproc_per_node=8 --rdzv_endpoint=algo-1:29400 --rdzv_id=100 hello.py --conf gpt-neox/sai_vishwa_15B.yml\u001b[0m\n",
      "\u001b[34mWARNING:torch.distributed.run:\u001b[0m\n",
      "\u001b[34m*****************************************\u001b[0m\n",
      "\u001b[34mSetting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[34m*****************************************\u001b[0m\n",
      "\u001b[35mWARNING:torch.distributed.run:\u001b[0m\n",
      "\u001b[35m*****************************************\u001b[0m\n",
      "\u001b[35mSetting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[35m*****************************************\u001b[0m\n",
      "\u001b[34marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[34marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[34marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[34marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[34marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[34marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[34marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[34marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[34mHello from host algo-1 rank 0\u001b[0m\n",
      "\u001b[34mHello from host algo-1 rank 5\u001b[0m\n",
      "\u001b[34mHello from host algo-1 rank 2\u001b[0m\n",
      "\u001b[34mHello from host algo-1 rank 6Hello from host algo-1 rank 1\u001b[0m\n",
      "\u001b[34mHello from host algo-1 rank 7\u001b[0m\n",
      "\u001b[34mHello from host algo-1 rank 3\u001b[0m\n",
      "\u001b[34mHello from host algo-1 rank 4\u001b[0m\n",
      "\u001b[35marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[35marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[35marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[35marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[35marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[35marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[35marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[35marguments are ['hello.py', '--conf', 'gpt-neox/sai_vishwa_15B.yml']\u001b[0m\n",
      "\u001b[35mHello from host algo-2 rank 15\u001b[0m\n",
      "\u001b[35mHello from host algo-2 rank 12\u001b[0m\n",
      "\u001b[35mHello from host algo-2 rank 13\u001b[0m\n",
      "\u001b[35mHello from host algo-2 rank 11\u001b[0m\n",
      "\u001b[35mHello from host algo-2 rank 10\u001b[0m\n",
      "\u001b[35mHello from host algo-2 rank 9\u001b[0m\n",
      "\u001b[35mHello from host algo-2 rank 14\u001b[0m\n",
      "\u001b[35mHello from host algo-2 rank 8\u001b[0m\n",
      "\u001b[34mhello.py exiting\u001b[0m\n",
      "\u001b[34mhello.py exiting\u001b[0m\n",
      "\u001b[34mhello.py exitinghello.py exiting\u001b[0m\n",
      "\u001b[34mhello.py exiting\u001b[0m\n",
      "\u001b[34mhello.py exiting\u001b[0m\n",
      "\u001b[34mhello.py exiting\u001b[0m\n",
      "\u001b[34mhello.py exiting\u001b[0m\n",
      "\u001b[35mhello.py exiting\u001b[0m\n",
      "\u001b[35mhello.py exiting\u001b[0m\n",
      "\u001b[35mhello.py exiting\u001b[0m\n",
      "\u001b[35mhello.py exitinghello.py exiting\u001b[0m\n",
      "\u001b[35mhello.py exiting\u001b[0m\n",
      "\u001b[35mhello.py exiting\u001b[0m\n",
      "\u001b[35mhello.py exiting\u001b[0m\n",
      "\u001b[35mJob finished!\u001b[0m\n",
      "\u001b[35m2023-05-02 01:22:08,711 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2023-05-02 01:22:08,711 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[35m2023-05-02 01:22:08,712 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mJob finished!\u001b[0m\n",
      "\u001b[34m2023-05-02 01:22:08,707 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-05-02 01:22:08,707 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-05-02 01:22:08,707 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-05-02 01:22:32 Uploading - Uploading generated training model\n",
      "2023-05-02 01:22:32 Completed - Resource retained for reuse\n",
      "Training seconds: 106\n",
      "Billable seconds: 106\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "estimator = PyTorch(\n",
    "    base_job_name=\"topology-inference-mpi\",\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"topology_aware_launcher.py\",\n",
    "    role=role,\n",
    "    image_uri=\"570106654206.dkr.ecr.us-east-1.amazonaws.com/megatron-deepspeed:pt1.13.1-deeperspeed-0.8.3-v1\",\n",
    "    # For training with multinode distributed training, set this count. Example: 2\n",
    "    instance_count=2,\n",
    "    # For training with p3dn instance use - ml.p3dn.24xlarge, with p4dn instance use - ml.p4d.24xlarge\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    # Training using SMDataParallel Distributed Training Framework\n",
    "    debugger_hook_config=False,\n",
    "    keep_alive_period_in_seconds=3600,\n",
    "    hyperparameters = {'pp-degree': 2, 'dp-degree': 1,\n",
    "                       'optimize-for-pp': 'True', 'dp-major': 'True', \n",
    "                       'entry-point': 'hello.py', \n",
    "                       'bad-placement': False,\n",
    "                       'conf': 'gpt-neox/sai_vishwa_15B.yml', \n",
    "                       }\n",
    ")\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
